{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the csv file and convert features to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the spark path \n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local\") \\\n",
    "     .appName(\"hotels\") \\\n",
    "     .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"../input/Hotels_data_Changed.csv\", header=True)\n",
    "# Transform string values to numeric\n",
    "indexers = [StringIndexer(inputCol=\"WeekDay\", outputCol=\"WeekDayIndex\"),\n",
    "            StringIndexer(inputCol=\"Hotel Name\", outputCol=\"HotelNameIndex\"),]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import pandas as pd\n",
    "\n",
    "#Transform date values to numeric\n",
    "dateFormatter = udf(lambda x:  pd.to_datetime(x).toordinal(), IntegerType())\n",
    "\n",
    "indexed_df = indexed_df.withColumn('SnapshotDateIndex', dateFormatter(col('Snapshot Date')))\n",
    "indexed_df = indexed_df.withColumn('CheckinDateIndex', dateFormatter(col('Checkin Date')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the highest discount code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowToKeyValue(row):\n",
    "    key = (row['WeekDayIndex'], row[\"SnapshotDateIndex\"], row[\"CheckinDateIndex\"], row[\"DayDiff\"], row[\"HotelNameIndex\"])\n",
    "    val = (row['DiscountPerc'], row[\"Discount Code\"])\n",
    "    return (key,val)\n",
    "\n",
    "def reduceToMaxPrice(val1, val2):\n",
    "    price1, code1 = val1\n",
    "    price2, code2 = val2\n",
    "    if (price1 > price2):\n",
    "        return (price1, code1)\n",
    "    else:\n",
    "        return (price2, code2)\n",
    "    \n",
    "rdd = indexed_df.rdd.map(rowToKeyValue)\\\n",
    "    .reduceByKey(reduceToMaxPrice)\\\n",
    "    .mapValues(lambda val: val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test & training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "def mapToLabeledPoint(tup):\n",
    "    key, val = tup\n",
    "    # Change range of values from 1-4 to 0-3\n",
    "    return LabeledPoint(int(val) -1, list(key))\n",
    "\n",
    "# Split into test and train data\n",
    "test_data, training_data = rdd.map(mapToLabeledPoint).randomSplit(weights=[0.3, 0.7], seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features 0: Week Day\n",
      "features 1: Snapshot Date\n",
      "features 2: Checkin Date\n",
      "features 3: Day Diff\n",
      "features 4: Hotel Name\n",
      "DecisionTreeModel classifier of depth 5 with 63 nodes\n",
      "  If (feature 0 <= 5.0)\n",
      "   If (feature 4 <= 12.0)\n",
      "    If (feature 0 <= 4.0)\n",
      "     If (feature 0 <= 0.0)\n",
      "      If (feature 4 <= 0.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 0.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 0.0)\n",
      "      If (feature 4 <= 4.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 4 > 4.0)\n",
      "       Predict: 3.0\n",
      "    Else (feature 0 > 4.0)\n",
      "     If (feature 4 <= 9.0)\n",
      "      If (feature 4 <= 0.0)\n",
      "       Predict: 3.0\n",
      "      Else (feature 4 > 0.0)\n",
      "       Predict: 2.0\n",
      "     Else (feature 4 > 9.0)\n",
      "      If (feature 2 <= 735906.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 735906.0)\n",
      "       Predict: 1.0\n",
      "   Else (feature 4 > 12.0)\n",
      "    If (feature 0 <= 4.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      If (feature 0 <= 0.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 0.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      If (feature 0 <= 3.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 3.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 0 > 4.0)\n",
      "     If (feature 4 <= 127.0)\n",
      "      If (feature 4 <= 23.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 4 > 23.0)\n",
      "       Predict: 2.0\n",
      "     Else (feature 4 > 127.0)\n",
      "      If (feature 3 <= 1.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 3 > 1.0)\n",
      "       Predict: 2.0\n",
      "  Else (feature 0 > 5.0)\n",
      "   If (feature 4 <= 127.0)\n",
      "    If (feature 4 <= 9.0)\n",
      "     If (feature 2 <= 735959.0)\n",
      "      If (feature 4 <= 2.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 2.0)\n",
      "       Predict: 1.0\n",
      "     Else (feature 2 > 735959.0)\n",
      "      If (feature 4 <= 6.0)\n",
      "       Predict: 3.0\n",
      "      Else (feature 4 > 6.0)\n",
      "       Predict: 3.0\n",
      "    Else (feature 4 > 9.0)\n",
      "     If (feature 1 <= 735893.0)\n",
      "      If (feature 4 <= 109.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 109.0)\n",
      "       Predict: 0.0\n",
      "     Else (feature 1 > 735893.0)\n",
      "      If (feature 4 <= 81.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 81.0)\n",
      "       Predict: 2.0\n",
      "   Else (feature 4 > 127.0)\n",
      "    If (feature 2 <= 735899.0)\n",
      "     If (feature 3 <= 1.0)\n",
      "      If (feature 4 <= 200.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 200.0)\n",
      "       Predict: 0.0\n",
      "     Else (feature 3 > 1.0)\n",
      "      If (feature 2 <= 735823.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 > 735823.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 2 > 735899.0)\n",
      "     If (feature 3 <= 1.0)\n",
      "      If (feature 4 <= 200.0)\n",
      "       Predict: 0.0\n",
      "      Else (feature 4 > 200.0)\n",
      "       Predict: 0.0\n",
      "     Else (feature 3 > 1.0)\n",
      "      If (feature 2 <= 735935.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 2 > 735935.0)\n",
      "       Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTree.trainClassifier(training_data, numClasses=4, \n",
    "                                          categoricalFeaturesInfo={},\n",
    "                                          impurity='entropy', maxDepth=5, maxBins=30)\n",
    "\n",
    "# Print results\n",
    "print('features 0: Week Day')\n",
    "print('features 1: Snapshot Date')\n",
    "print('features 2: Checkin Date')\n",
    "print('features 3: Day Diff')\n",
    "print('features 4: Hotel Name')\n",
    "print(tree_model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print decision tree statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.35379464285714285\n",
      "False positive rate 0.26186898736862246\n",
      "DenseMatrix([[1364., 3093., 1656.,  663.],\n",
      "             [ 873., 6545., 1974.,  836.],\n",
      "             [ 451., 5419., 2533.,  754.],\n",
      "             [ 414., 2959., 1752.,  970.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
    "predictionAndLabels = predictions.zip(test_data.map(lambda p: p.label))\n",
    "\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "print('Accuracy {}'.format(metrics.accuracy))\n",
    "print('False positive rate {}'.format(metrics.weightedFalsePositiveRate))\n",
    "print(metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.259734623015873\n",
      "False positive rate 0.2240254536536272\n",
      "DenseMatrix([[  84., 2222.,  208., 4262.],\n",
      "             [ 103., 3363.,  514., 6248.],\n",
      "             [  85., 2804.,  551., 5717.],\n",
      "             [  35., 1479.,  201., 4380.]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "\n",
    "# Train a naive Bayes model.\n",
    "model = NaiveBayes.train(training_data, 1.0)\n",
    "\n",
    "# Make prediction\n",
    "NaiveBayes_predictionAndLabel = test_data.map(lambda p: (float(model.predict(p.features)), p.label))\n",
    "\n",
    "naive_metrics = MulticlassMetrics(NaiveBayes_predictionAndLabel)\n",
    "\n",
    "print('Accuracy {}'.format(naive_metrics.accuracy))\n",
    "print('False positive rate {}'.format(naive_metrics.weightedFalsePositiveRate))\n",
    "print(naive_metrics.confusionMatrix())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
