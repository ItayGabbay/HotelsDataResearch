{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'findspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-207aeae9420a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Finds the spark path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'findspark'"
     ]
    }
   ],
   "source": [
    "# Finds the spark path \n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local\") \\\n",
    "     .appName(\"hotels\") \\\n",
    "     .getOrCreate()\n",
    "\n",
    "hotels_df = spark.read.csv(\"../input/Hotels_data_Changed.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the highest discount code for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "def rowToKeyValue(row):\n",
    "    key = (row['WeekDay'], row[\"Snapshot Date\"], row[\"Checkin Date\"], row[\"DayDiff\"], row[\"Hotel Name\"])\n",
    "    val = ([row[\"Discount Code\"]], row['DiscountPerc'])\n",
    "    return (key,val)\n",
    "\n",
    "def reduceToMaxDiscountPerKey(val1, val2):\n",
    "    codes1, discount1 = val1\n",
    "    codes2, discount2 = val2\n",
    "    if (discount1 > discount2):\n",
    "        return val1\n",
    "    elif(discount2 > discount1):\n",
    "        return val2\n",
    "    else: # In case the discounts are equals, merge the prices to same array\n",
    "        return (codes1+ codes2, discount1)\n",
    "\n",
    "def flatMapDiscountCodes(row):\n",
    "    key, val = row\n",
    "    codes = val[0]\n",
    "    # Return list of key & code\n",
    "    return [(key, code) for code in codes]\n",
    "\n",
    "def rddToRow(rddRow):\n",
    "    return Row(WeekDay=rddRow[0][0], SnapshotDate=rddRow[0][1], CheckinDate=rddRow[0][2],\\\n",
    "                DayDiff=rddRow[0][3], HotelName=rddRow[0][4], DiscountCode=rddRow[1])\n",
    "\n",
    "hotelsBestDiscountCode_df = hotels_df.rdd\\\n",
    "                .map(rowToKeyValue)\\\n",
    "                .reduceByKey(reduceToMaxDiscountPerKey)\\\n",
    "                .flatMap(flatMapDiscountCodes)\\\n",
    "                .map(rddToRow).toDF()\n",
    "hotelsBestDiscountCode_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pandas as pd\n",
    "\n",
    "# Transform string values to numeric\n",
    "indexers = [StringIndexer(inputCol=\"WeekDay\", outputCol=\"WeekDayIndex\"),\n",
    "            StringIndexer(inputCol=\"HotelName\", outputCol=\"HotelNameIndex\"),]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "hotelsWithIndexedStrings_df = pipeline.fit(hotelsBestDiscountCode_df).transform(hotelsBestDiscountCode_df)\n",
    "\n",
    "# Extract date values\n",
    "dateYearValue = udf(lambda x: pd.to_datetime(x).year, IntegerType())\n",
    "dateDayValue = udf(lambda x: pd.to_datetime(x).day, IntegerType())\n",
    "dateMonthValue = udf(lambda x: pd.to_datetime(x).month, IntegerType())\n",
    "\n",
    "hotelsWithDateIndexed_df = hotelsWithIndexedStrings_df\\\n",
    "                     .withColumn('SnapshotDateYear', dateYearValue(col('SnapshotDate')))\\\n",
    "                     .withColumn('SnapshotDateMonth', dateMonthValue(col('SnapshotDate')))\\\n",
    "                     .withColumn('SnapshotDateDay', dateDayValue(col('SnapshotDate')))\\\n",
    "                     .withColumn('CheckinDateYear', dateYearValue(col('CheckinDate')))\\\n",
    "                     .withColumn('CheckinDateMonth', dateMonthValue(col('CheckinDate')))\\\n",
    "                     .withColumn('CheckinDateDay', dateDayValue(col('CheckinDate')))\n",
    "# Convert string column to int\n",
    "hotelsWithIntCoulmn_df = hotelsWithDateIndexed_df.withColumn(\"DayDiff\",\\\n",
    "                                   hotelsWithDateIndexed_df[\"DayDiff\"].cast(\"integer\"))\\\n",
    "                                .withColumn('DiscountCode', hotelsWithDateIndexed_df['DiscountCode'].cast('integer'))\n",
    "\n",
    "# Remove unneccesary columns\n",
    "hotelsWithoutColumns_df = hotelsWithIntCoulmn_df.drop('SnapshotDate').drop('CheckinDate')\\\n",
    "                         .drop('HotelName').drop('WeekDay')\n",
    "hotelsWithoutColumns_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "def transposeDF(df):\n",
    "    pandas_df = df.toPandas().transpose().reset_index()\n",
    "    return spark.createDataFrame(pandas_df)\n",
    "    \n",
    "# Show distinct values count\n",
    "distinctValuesDF = hotelsWithoutColumns_df.agg(*(countDistinct(col(c)).alias(c) for c in hotelsWithoutColumns_df.columns));\n",
    "transposeDF(distinctValuesDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns statsitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "describe_df = hotelsWithoutColumns_df.describe(hotelsWithoutColumns_df.columns);\n",
    "transposeDF(describe_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in hotelsWithoutColumns_df.columns:\n",
    "    corr = hotelsWithoutColumns_df.corr('DiscountCode', column)\n",
    "    print(\"Column %s correlation: %s\" % (column, corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create vector of all features expect the label\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[x for x in hotelsWithoutColumns_df.columns if x != 'DiscountCode'],\n",
    "    outputCol='features')\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = hotelsWithoutColumns_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol='DiscountCode', featuresCol='features',\\\n",
    "                            impurity='entropy', maxDepth=20, maxBins=554)\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "tree_model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions.\n",
    "predictions = tree_model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"DiscountCode\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"DiscountCode\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuaracy = %g \" %  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print decision tree auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Binary classifications\n",
    "for label in range(1,5):\n",
    "    # Filter only relevanot to class predictions\n",
    "    predictions.where(\"prediction == %s OR DiscountCode == %s\" % (label, label)).select('prediction', 'DiscountCode')\n",
    "                .withColumn('binaryPrediction', F.when(col('prediction')==label,1.0).otherwise(0.0))\\\n",
    "                .withColumn('binaryDiscountCode', F.when(col('DiscountCode')==label,1.0).otherwise(0.0))\n",
    "            \n",
    "    binaryPredictions.select('prediction', 'DiscountCode', 'binaryPrediction', 'binaryDiscountCode').show(5)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"binaryPrediction\", labelCol=\"binaryDiscountCode\")\n",
    "    auc = evaluator.evaluate(binaryPredictions)\n",
    "    \n",
    "    print(\"Class %s area under roc = %s\" % (label, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-992c746d8614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlabelPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"prediction == %s OR DiscountCode == %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DiscountCode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelPredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreeExpected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtreePredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for label in range(1, 5):\n",
    "    labelPredictions = predictions.where(\"prediction == %s OR DiscountCode == %s\" % (label, label))\\\n",
    "            .select('prediction', 'DiscountCode').collect()\n",
    "    \n",
    "    expected = labelPredictions.map(lambda x : x[0])\n",
    "    predicted = labelPredictions.map(lambda x : x[1])\n",
    "\n",
    "    fpr[i], tpr[i], _ = roc_curve(expected, predicted, pos_label=label)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(1, 5)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(1, 5):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 4\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "lw=2\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red'])\n",
    "for i, color in zip(range(1,5), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i+1.0, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run naive bayes - old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "\n",
    "model = NaiveBayes.train(training_data, 1.0)\n",
    "\n",
    "NaiveBayes_predictionAndLabel = test_data.map(lambda p: (float(model.predict(p.features)), p.label))\n",
    "\n",
    "naive_metrics = MulticlassMetrics(NaiveBayes_predictionAndLabel)\n",
    "\n",
    "print('Accuracy {}'.format(naive_metrics.accuracy))\n",
    "print('False positive rate {}'.format(naive_metrics.weightedFalsePositiveRate))\n",
    "print(naive_metrics.confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run naive bayes - new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = hotelsWithoutColumns_df.randomSplit([0.9, 0.1])\n",
    "\n",
    "# Train a NaiveBayes model.\n",
    "dt = NaiveBayes(labelCol='DiscountCode', featuresCol='features')\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "naive_model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions.\n",
    "naive_predictions = naive_model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "naive_predictions.select(\"prediction\", \"DiscountCode\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"DiscountCode\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Accuaracy = %g \" %  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print naive bayes auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Binary classifications\n",
    "for label in range(1,5):\n",
    "    # Filter only relevanot to class predictions\n",
    "    binaryPredictions = naive_predictions.where(\"prediction == %s OR DiscountCode == %s\" % (label, label))\\\n",
    "                .withColumn('binaryPrediction', F.when(col('prediction')==label,1.0).otherwise(0.0))\\\n",
    "                .withColumn('binaryDiscountCode', F.when(col('DiscountCode')==label,1.0).otherwise(0.0))\n",
    "            \n",
    "    binaryPredictions.select('prediction', 'DiscountCode', 'binaryPrediction', 'binaryDiscountCode').show(5)\n",
    "    \n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"binaryPrediction\", labelCol=\"binaryDiscountCode\")\n",
    "    auc = evaluator.evaluate(binaryPredictions)\n",
    "    \n",
    "    print(\"Class %s area under roc = %s\" % (label, auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for label in range(1, 5):\n",
    "    labelPredictions = naive_predictions.where(\"prediction == %s OR DiscountCode == %s\" % (label, label))\\\n",
    "            .select('prediction', 'DiscountCode').collect()\n",
    "    \n",
    "    expected = labelPredictions.map(lambda x : x[0])\n",
    "    predicted = labelPredictions.map(lambda x : x[1])\n",
    "\n",
    "    fpr[i], tpr[i], _ = roc_curve(expected, predicted, pos_label=label)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(1, 5)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(1, 5):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 4\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "lw=2\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red'])\n",
    "for i, color in zip(range(1,5), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i+1.0, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
