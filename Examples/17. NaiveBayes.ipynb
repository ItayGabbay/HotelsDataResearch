{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (the easy way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll cheat by using sklearn.naive_bayes to train a spam classifier! Most of the code is just loading our training data into a pandas DataFrame that we can play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "\n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "\n",
    "    return DataFrame(rows, index=index)\n",
    "\n",
    "data = DataFrame({'message': [], 'class': []})\n",
    "\n",
    "data = data.append(dataFrameFromDirectory('C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue', 'spamtrue'))\n",
    "data = data.append(dataFrameFromDirectory('C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamfalse', 'spamfalse'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at that DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue\\00001.7848dde101aa985090474a91ec93fcf0</th>\n",
       "      <td>spamtrue</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue\\00002.d94f1b97e48ed3b553b3508d116e6a09</th>\n",
       "      <td>spamtrue</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue\\00003.2ee33bc6eacdb11f38d052c44819ba6c</th>\n",
       "      <td>spamtrue</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue\\00004.eac8de8d759b7e74154f142194282724</th>\n",
       "      <td>spamtrue</td>\n",
       "      <td>##############################################...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C:\\Shay\\Personal\\Colman\\DataScience\\ShayNotebooks\\spamemails\\spamtrue\\00005.57696a39d7d84318ce497886896bf90d</th>\n",
       "      <td>spamtrue</td>\n",
       "      <td>I thought you might like these:\\n\\n1) Slim Dow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       class  \\\n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  spamtrue   \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  spamtrue   \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  spamtrue   \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  spamtrue   \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  spamtrue   \n",
       "\n",
       "                                                                                              message  \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...  \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...  \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  ##############################################...  \n",
       "C:\\Shay\\Personal\\Colman\\DataScience\\ShayNoteboo...  I thought you might like these:\\n\\n1) Slim Dow...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a CountVectorizer to split up each message into its list of words, and throw that into a MultinomialNB classifier. Call fit() and we've got a trained spam filter ready to go! It's just that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20104)\t1\n",
      "  (0, 15629)\t1\n",
      "  (0, 30882)\t1\n",
      "  (0, 50553)\t1\n",
      "  (0, 36099)\t1\n",
      "  (0, 44217)\t1\n",
      "  (0, 58467)\t1\n",
      "  (0, 51216)\t1\n",
      "  (0, 10966)\t1\n",
      "  (0, 47038)\t1\n",
      "  (0, 46816)\t1\n",
      "  (0, 54656)\t1\n",
      "  (0, 43219)\t2\n",
      "  (0, 16635)\t1\n",
      "  (0, 38953)\t1\n",
      "  (0, 14434)\t1\n",
      "  (0, 16777)\t1\n",
      "  (0, 36134)\t1\n",
      "  (0, 35030)\t1\n",
      "  (0, 46819)\t1\n",
      "  (0, 12870)\t1\n",
      "  (0, 58727)\t1\n",
      "  (0, 22787)\t1\n",
      "  (0, 22197)\t2\n",
      "  (0, 53337)\t2\n",
      "  :\t:\n",
      "  (2999, 12870)\t2\n",
      "  (2999, 53337)\t1\n",
      "  (2999, 24806)\t2\n",
      "  (2999, 28034)\t1\n",
      "  (2999, 10697)\t1\n",
      "  (2999, 40368)\t2\n",
      "  (2999, 40892)\t4\n",
      "  (2999, 15189)\t1\n",
      "  (2999, 39016)\t1\n",
      "  (2999, 30375)\t5\n",
      "  (2999, 58736)\t1\n",
      "  (2999, 26143)\t2\n",
      "  (2999, 55923)\t1\n",
      "  (2999, 47451)\t1\n",
      "  (2999, 53220)\t12\n",
      "  (2999, 10746)\t5\n",
      "  (2999, 56678)\t1\n",
      "  (2999, 31369)\t6\n",
      "  (2999, 27728)\t5\n",
      "  (2999, 60793)\t6\n",
      "  (2999, 37734)\t1\n",
      "  (2999, 40661)\t4\n",
      "  (2999, 53745)\t6\n",
      "  (2999, 14755)\t1\n",
      "  (2999, 28855)\t1\n"
     ]
    }
   ],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spamfalse' 'spamtrue' 'spamfalse']\n"
     ]
    }
   ],
   "source": [
    "examples = [\"Hi Bob, how about a game of golf tomorrow?\", \"dear friend\", \"Free!\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is small, so our spam classifier isn't actually very good. Try running some different test emails through it and see if you get the results you expect.\n",
    "\n",
    "If you really want to challenge yourself, try applying train/test to this spam classifier - see how well it can predict some subset of the ham and spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
